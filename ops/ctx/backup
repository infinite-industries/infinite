#!/bin/sh
# 
#  Create backups of a postgres database, copy them to S3
#

set -o errexit

# directory on the host where backups are stored
BACKUP_DIR=${BACKUP_DIR:="/var/tmp/backups"}

# timestamp
TS=$(date -u +%Y-%m-%dT%H:%M:%S)

# number of days of backup retention
NUM_DAYS=${NUM_DAYS:=10}

#
# MAIN SCRIPT 
#

# create dumpfile
pg_dump -d "sslmode=require" -Fc -f ${BACKUP_DIR}/${PGDATABASE}.dump.${TS}

# create sql dump - no perms
pg_dump -d "sslmode=require" -Fp --no-owner --no-acl \
  | gzip -c > ${BACKUP_DIR}/${PGDATABASE}.${TS}.gz

# There is an an alternate way to create the sql dump using the full dump
#pg_restore --no-owner --no-acl -f - /var/tmp/backups/${PGDATABASE}.$TS \
#  | gzip -c > ${BACKUP_DIR}/${PGDATABASE}.sql.${TS}.gz

# create anonymized versions of the sql dump
gzip -dc ${BACKUP_DIR}/${PGDATABASE}.${TS}.gz \
  | perl -pE 's/[\w._+-]+@[\w._-]+\.[\w_-]+/nobody\@example.com/g' \
  | gzip -c > ${BACKUP_DIR}/${PGDATABASE}.anon.${TS}.gz

# create latest symlinks
ln -sf ${PGDATABASE}.dump.${TS} ${BACKUP_DIR}/${PGDATABASE}.dump
ln -sf ${PGDATABASE}.${TS}.gz ${BACKUP_DIR}/${PGDATABASE}.gz
ln -sf ${PGDATABASE}.anon.${TS}.gz ${BACKUP_DIR}/${PGDATABASE}.anon.gz

# copy to S3
aws s3 cp ${BACKUP_DIR}/${PGDATABASE}.dump s3://${S3_BUCKET}/${S3_PATH}/ >/dev/null 2>&1
aws s3 cp ${BACKUP_DIR}/${PGDATABASE}.gz s3://${S3_BUCKET}/${S3_PATH}/ >/dev/null 2>&1
aws s3 cp ${BACKUP_DIR}/${PGDATABASE}.anon.gz s3://${S3_BUCKET}/${S3_PATH}/ >/dev/null 2>&1

# delete files older than NUM_DAYS old
find ${BACKUP_DIR} -type f -mtime +${NUM_DAYS} -name "${PGDATABASE}*" -exec rm {} \;
